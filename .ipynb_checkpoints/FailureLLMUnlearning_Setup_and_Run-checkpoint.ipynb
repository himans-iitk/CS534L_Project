{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FailureLLMUnlearning - Complete Setup and Execution Guide\n",
    "\n",
    "This notebook provides a step-by-step guide to:\n",
    "1. Clone the repository\n",
    "2. Set up the conda environment\n",
    "3. Install all dependencies\n",
    "4. Load data from HuggingFace\n",
    "5. Run unlearning methods\n",
    "6. Evaluate the results\n",
    "\n",
    "**Paper**: Catastrophic Failure of LLM Unlearning via Quantization (ICLR 2025)\n",
    "**Repository**: https://github.com/zzwjames/FailureLLMUnlearning.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Clone the Repository\n",
    "\n",
    "First, we'll clone the repository if it doesn't already exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed /workspace/CS534L_Project/FailureLLMUnlearning/ckpt\n",
      "Removed /workspace/CS534L_Project/FailureLLMUnlearning/temp\n",
      "Not found: /workspace/CS534L_Project/FailureLLMUnlearning/results\n"
     ]
    }
   ],
   "source": [
    "import shutil, pathlib\n",
    "\n",
    "root = pathlib.Path(\"/workspace/CS534L_Project/FailureLLMUnlearning\")\n",
    "dirs_to_remove = [\n",
    "    root / \"ckpt\",\n",
    "    root / \"temp\",\n",
    "    root / \"results\",\n",
    "]\n",
    "\n",
    "for d in dirs_to_remove:\n",
    "    if d.exists():\n",
    "        shutil.rmtree(d)\n",
    "        print(f\"Removed {d}\")\n",
    "    else:\n",
    "        print(f\"Not found: {d}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already exists at: /workspace/CS534L_Project/FailureLLMUnlearning\n",
      "Skipping clone step. If you want to re-clone, delete the directory first.\n",
      "\n",
      "Current working directory: /workspace/CS534L_Project/FailureLLMUnlearning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the project directory\n",
    "project_dir = Path(\"/workspace/CS534L_Project\")\n",
    "repo_dir = project_dir / \"FailureLLMUnlearning\"\n",
    "repo_url = \"https://github.com/zzwjames/FailureLLMUnlearning.git\"\n",
    "\n",
    "# Check if repository already exists\n",
    "if repo_dir.exists():\n",
    "    print(f\"Repository already exists at: {repo_dir}\")\n",
    "    print(\"Skipping clone step. If you want to re-clone, delete the directory first.\")\n",
    "else:\n",
    "    print(f\"Cloning repository from {repo_url}...\")\n",
    "    os.chdir(project_dir)\n",
    "    result = subprocess.run(\n",
    "        [\"git\", \"clone\", repo_url],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úì Repository cloned successfully!\")\n",
    "    else:\n",
    "        print(f\"‚úó Error cloning repository: {result.stderr}\")\n",
    "        raise Exception(\"Failed to clone repository\")\n",
    "\n",
    "# Change to repository directory\n",
    "os.chdir(repo_dir)\n",
    "print(f\"\\nCurrent working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Conda Environment\n",
    "\n",
    "According to the README, we need to create a conda environment using the `environment.yml` file. This will create an environment named `py310` with Python 3.10 and all required dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'conda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check if conda is available\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--version\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö† Warning: Conda is not available. Please install conda or use pip instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.12/subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/usr/lib/python3.12/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/usr/lib/python3.12/subprocess.py:1955\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'conda'"
     ]
    }
   ],
   "source": [
    "# Check if conda is available\n",
    "result = subprocess.run([\"conda\", \"--version\"], capture_output=True, text=True)\n",
    "if result.returncode != 0:\n",
    "    print(\"‚ö† Warning: Conda is not available. Please install conda or use pip instead.\")\n",
    "    print(\"You can still proceed with pip installation in the next step.\")\n",
    "else:\n",
    "    print(f\"‚úì Conda found: {result.stdout.strip()}\")\n",
    "    \n",
    "# Check if environment.yml exists\n",
    "env_file = repo_dir / \"environment.yml\"\n",
    "if env_file.exists():\n",
    "    print(f\"‚úì Found environment.yml at: {env_file}\")\n",
    "    print(\"\\nTo create the conda environment, run the following commands in your terminal:\")\n",
    "    print(f\"  conda env create -f {env_file}\")\n",
    "    print(\"  conda activate py310\")\n",
    "    print(\"\\nOr if the environment already exists, just activate it:\")\n",
    "    print(\"  conda activate py310\")\n",
    "else:\n",
    "    print(\"‚úó environment.yml not found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Dependencies\n",
    "\n",
    "We'll install dependencies using pip. The repository provides both `environment.yml` (for conda) and `requirements.txt` (for pip). We'll use pip for compatibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements from requirements.txt:\n",
      "============================================================\n",
      "accelerate==0.29\n",
      "bitsandbytes==0.42.0\n",
      "datasets==2.19\n",
      "einops==0.7\n",
      "huggingface-hub>=0.26.0,<1.0\n",
      "ipykernel==6.29\n",
      "ipython==8.24\n",
      "ipywidgets==8.1\n",
      "matplotlib==3.9\n",
      "matplotlib-inline==0.1\n",
      "numpy==1.26\n",
      "openai==1.23\n",
      "pandas==2.2\n",
      "peft==0.13.2\n",
      "protobuf==5.26\n",
      "python-dotenv==1.0\n",
      "rouge==1.0.1\n",
      "rouge-score==0.1\n",
      "scienceplots==2.1\n",
      "scikit-learn==1.4\n",
      "scipy==1.13\n",
      "seaborn==0.13\n",
      "sympy==1.12\n",
      "tokenizers==0.19\n",
      "torch==2.2\n",
      "tqdm\n",
      "transformers==4.40\n",
      "trl>=0.8.1\n",
      "\n",
      "============================================================\n",
      "\n",
      "‚ö† Note: Installing packages can take several minutes.\n",
      "The main dependencies include:\n",
      "  - torch==2.2\n",
      "  - transformers==4.40\n",
      "  - accelerate==0.29\n",
      "  - datasets==2.19\n",
      "  - bitsandbytes==0.42.0 (optional, requires CUDA/Linux)\n",
      "  - and many more...\n"
     ]
    }
   ],
   "source": [
    "# Read requirements.txt to see what will be installed\n",
    "requirements_file = repo_dir / \"requirements.txt\"\n",
    "if requirements_file.exists():\n",
    "    print(\"Requirements from requirements.txt:\")\n",
    "    print(\"=\" * 60)\n",
    "    with open(requirements_file, 'r') as f:\n",
    "        print(f.read())\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Note: We'll install these in the next cell\n",
    "    print(\"\\n‚ö† Note: Installing packages can take several minutes.\")\n",
    "    print(\"The main dependencies include:\")\n",
    "    print(\"  - torch==2.2\")\n",
    "    print(\"  - transformers==4.40\")\n",
    "    print(\"  - accelerate==0.29\")\n",
    "    print(\"  - datasets==2.19\")\n",
    "    print(\"  - bitsandbytes==0.42.0 (optional, requires CUDA/Linux)\")\n",
    "    print(\"  - and many more...\")\n",
    "else:\n",
    "    print(\"‚úó requirements.txt not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies from requirements.txt...\n",
      "This may take several minutes. Please be patient...\n",
      "\n",
      "Step 1: Installing core dependencies (excluding bitsandbytes)...\n",
      "‚úì Core dependencies installed successfully!\n",
      "\n",
      "Step 2: Attempting to install bitsandbytes (optional for quantization)...\n",
      "‚úì bitsandbytes installed successfully!\n",
      "  You can use 4-bit and 8-bit quantization.\n",
      "\n",
      "============================================================\n",
      "Installation summary:\n",
      "  - Core dependencies: ‚úì\n",
      "  - bitsandbytes: ‚úì (quantization available)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "# This may take 10-20 minutes depending on your internet connection\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "print(\"Installing dependencies from requirements.txt...\")\n",
    "print(\"This may take several minutes. Please be patient...\\n\")\n",
    "\n",
    "# Check if we're on macOS (bitsandbytes doesn't work on macOS/ARM)\n",
    "is_macos = platform.system() == \"Darwin\"\n",
    "is_arm = platform.machine() == \"arm64\"\n",
    "\n",
    "if is_macos:\n",
    "    print(\"‚ö† Detected macOS system.\")\n",
    "    print(\"Note: bitsandbytes requires CUDA (Linux/NVIDIA GPU) and won't work on macOS.\")\n",
    "    print(\"The code will work in full-precision mode without bitsandbytes.\\n\")\n",
    "\n",
    "# Create a temporary requirements file without bitsandbytes for initial installation\n",
    "temp_requirements = repo_dir / \"requirements_temp.txt\"\n",
    "with open(requirements_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Filter out bitsandbytes line\n",
    "filtered_lines = [line for line in lines if not line.strip().startswith('bitsandbytes')]\n",
    "\n",
    "with open(temp_requirements, 'w') as f:\n",
    "    f.writelines(filtered_lines)\n",
    "\n",
    "print(\"Step 1: Installing core dependencies (excluding bitsandbytes)...\")\n",
    "result = subprocess.run(\n",
    "    [\"pip\", \"install\", \"-r\", str(temp_requirements)],\n",
    "    cwd=str(repo_dir),\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úì Core dependencies installed successfully!\")\n",
    "else:\n",
    "    print(\"‚úó Error installing core dependencies:\")\n",
    "    print(result.stderr)\n",
    "    print(\"\\nTrying to continue anyway...\")\n",
    "\n",
    "# Try to install bitsandbytes separately (will fail on macOS, which is OK)\n",
    "print(\"\\nStep 2: Attempting to install bitsandbytes (optional for quantization)...\")\n",
    "bitsandbytes_result = subprocess.run(\n",
    "    [\"pip\", \"install\", \"bitsandbytes==0.42.0\"],\n",
    "    cwd=str(repo_dir),\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if bitsandbytes_result.returncode == 0:\n",
    "    print(\"‚úì bitsandbytes installed successfully!\")\n",
    "    print(\"  You can use 4-bit and 8-bit quantization.\")\n",
    "elif is_macos:\n",
    "    print(\"‚ö† bitsandbytes installation skipped (not available on macOS).\")\n",
    "    print(\"  This is expected. You can still run the code in full-precision mode.\")\n",
    "    print(\"  Set quantize_4bit=0 and quantize_8bit=0 in evaluation.\")\n",
    "else:\n",
    "    print(\"‚ö† bitsandbytes installation failed:\")\n",
    "    print(bitsandbytes_result.stderr)\n",
    "    print(\"  You can still run the code in full-precision mode.\")\n",
    "\n",
    "# Clean up temp file\n",
    "if temp_requirements.exists():\n",
    "    temp_requirements.unlink()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Installation summary:\")\n",
    "print(\"  - Core dependencies: ‚úì\")\n",
    "if bitsandbytes_result.returncode == 0:\n",
    "    print(\"  - bitsandbytes: ‚úì (quantization available)\")\n",
    "else:\n",
    "    print(\"  - bitsandbytes: ‚úó (quantization not available, use full-precision)\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n",
      "GPU name: NVIDIA A100-SXM4-80GB\n",
      "GPU memory (MB): 81155\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device in use:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "    print(\"GPU memory (MB):\", torch.cuda.get_device_properties(0).total_memory // (1024**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Data from HuggingFace\n",
    "\n",
    "According to the README, we need to load data from HuggingFace datasets. This will download:\n",
    "- MUSE-News dataset and target model\n",
    "- MUSE-Books dataset and target model\n",
    "\n",
    "The data will be saved in the `data/` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4a: Authenticate with HuggingFace\n",
    "\n",
    "Some HuggingFace datasets require authentication. Let's check if you're logged in and authenticate if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking HuggingFace authentication...\n",
      "\n",
      "‚úì Already authenticated as: himishra\n",
      "  You can proceed to load data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check HuggingFace authentication and login if needed\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"Checking HuggingFace authentication...\\n\")\n",
    "\n",
    "# Check if huggingface_hub is installed\n",
    "try:\n",
    "    from huggingface_hub import whoami, login\n",
    "    hf_available = True\n",
    "except ImportError:\n",
    "    print(\"‚ö† huggingface_hub not found. Installing...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"huggingface_hub\"], capture_output=True)\n",
    "    from huggingface_hub import whoami, login\n",
    "    hf_available = True\n",
    "\n",
    "# Try to get current user info\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(f\"‚úì Already authenticated as: {user_info.get('name', 'Unknown')}\")\n",
    "    print(\"  You can proceed to load data.\\n\")\n",
    "    authenticated = True\n",
    "except Exception as e:\n",
    "    print(\"‚ö† Not authenticated with HuggingFace.\")\n",
    "    print(\"\\nTo authenticate, you have two options:\\n\")\n",
    "    print(\"Option 1: Login via CLI (Recommended)\")\n",
    "    print(\"  Run this command in your terminal:\")\n",
    "    print(\"    huggingface-cli login\")\n",
    "    print(\"  Then paste your access token when prompted.\\n\")\n",
    "    print(\"Option 2: Login programmatically\")\n",
    "    print(\"  Uncomment the code below and provide your token:\\n\")\n",
    "    print(\"  # token = 'your_huggingface_token_here'\")\n",
    "    print(\"  # login(token=token)\")\n",
    "    print(\"\\nTo get your token:\")\n",
    "    print(\"  1. Go to https://huggingface.co/settings/tokens\")\n",
    "    print(\"  2. Create a new token (or use an existing one)\")\n",
    "    print(\"  3. Copy the token and use it above\\n\")\n",
    "    \n",
    "    # Uncomment and set your token here if you want to login programmatically\n",
    "    authenticated = False\n",
    "    token = \"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\"\n",
    "    login(token=token)\n",
    "    print(\"‚úì Authenticated successfully!\")\n",
    "    authenticated = True        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Data directory already exists with content.\n",
      "Skipping data download. If you want to re-download, delete the data/ directory first.\n",
      "\n",
      "Data directory contents:\n",
      "  üìÅ books/\n",
      "  üìÅ news/\n"
     ]
    }
   ],
   "source": [
    "# Check if data already exists\n",
    "data_dir = repo_dir / \"data\"\n",
    "if data_dir.exists() and any(data_dir.iterdir()):\n",
    "    print(\"‚úì Data directory already exists with content.\")\n",
    "    print(\"Skipping data download. If you want to re-download, delete the data/ directory first.\")\n",
    "    print(f\"\\nData directory contents:\")\n",
    "    for item in sorted(data_dir.iterdir()):\n",
    "        if item.is_dir():\n",
    "            print(f\"  üìÅ {item.name}/\")\n",
    "else:\n",
    "    print(\"Data directory is empty or doesn't exist.\")\n",
    "    print(\"Will load data from HuggingFace in the next cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf_transfer\n",
      "  Using cached hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Using cached hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Installing collected packages: hf_transfer\n",
      "Successfully installed hf_transfer-0.1.9\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install hf_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from HuggingFace...\n",
      "This will download:\n",
      "  - MUSE-News dataset (knowmem, verbmem, privleak, raw, scal, sust)\n",
      "  - MUSE-Books dataset (knowmem, verbmem, privleak, raw)\n",
      "\n",
      "This may take 5-15 minutes depending on your connection...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data from HuggingFace\n",
    "# This will download datasets for both News and Books corpora\n",
    "# This may take some time depending on your internet connection\n",
    "\n",
    "print(\"Loading data from HuggingFace...\")\n",
    "print(\"This will download:\")\n",
    "print(\"  - MUSE-News dataset (knowmem, verbmem, privleak, raw, scal, sust)\")\n",
    "print(\"  - MUSE-Books dataset (knowmem, verbmem, privleak, raw)\")\n",
    "print(\"\\nThis may take 5-15 minutes depending on your connection...\\n\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"python\", \"load_data.py\"],\n",
    "    cwd=str(repo_dir),\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úì Data loaded successfully!\")\n",
    "    print(\"\\nData structure:\")\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(\"‚úó Error loading data:\")\n",
    "    print(result.stderr)\n",
    "    print(\"\\nYou may need to:\")\n",
    "    print(\"  1. Check your internet connection\")\n",
    "    print(\"  2. Ensure you have HuggingFace access\")\n",
    "    print(\"  3. Install huggingface-hub: pip install huggingface-hub\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run Unlearning Methods\n",
    "\n",
    "Now we'll run the unlearning methods. According to the README, we can use various algorithms:\n",
    "- `ga`: Gradient Ascent\n",
    "- `ga_gdr`: GA with Gradient Difference Regularization\n",
    "- `ga_klr`: GA with KL Regularization\n",
    "- `npo`: Negative Preference Optimization\n",
    "- `npo_gdr`: NPO with GDR\n",
    "- `npo_klr`: NPO with KLR\n",
    "- `ga_gdr_sure`, `ga_klr_sure`, `npo_gdr_sure`, `npo_klr_sure`: SURE variants\n",
    "- `rmu`: Retraining with Modified Updates\n",
    "\n",
    "We'll start with a simple example using the `ga` algorithm on the News corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlearning Configuration:\n",
      "============================================================\n",
      "Corpus: news\n",
      "Algorithm: ga\n",
      "Target Model: muse-bench/MUSE-News_target\n",
      "Forget Data: data/news/raw/forget.txt\n",
      "Retain Data: data/news/raw/retain1.txt\n",
      "Output Directory: ./ckpt/news/ga\n",
      "Epochs: 10\n",
      "Learning Rate: 1e-5\n",
      "Batch Size: 2\n",
      "GPU Devices: 0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Configuration for unlearning\n",
    "import os\n",
    "\n",
    "# Set corpus (options: 'news' or 'books')\n",
    "CORPUS = 'news'  # Change to 'books' if you want to use Books corpus\n",
    "\n",
    "# Set algorithm (options: 'ga', 'ga_gdr', 'ga_klr', 'npo', 'npo_gdr', 'npo_klr', \n",
    "#                        'ga_gdr_sure', 'ga_klr_sure', 'npo_gdr_sure', 'npo_klr_sure', 'rmu')\n",
    "ALGO = 'ga'  # Start with simple gradient ascent\n",
    "\n",
    "# Paths\n",
    "FORGET = f\"data/{CORPUS}/raw/forget.txt\"\n",
    "RETAIN = f\"data/{CORPUS}/raw/retain1.txt\"\n",
    "TARGET_DIR = f'muse-bench/MUSE-{CORPUS.capitalize()}_target'\n",
    "TOKENIZER_DIR = 'meta-llama/Llama-2-7b-hf'\n",
    "OUT_DIR = f\"./ckpt/{CORPUS}/{ALGO}\"\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_LEN = 2048\n",
    "EPOCHS = 10  # You may want to reduce this for testing (e.g., 1-2 epochs)\n",
    "LR = '1e-5'\n",
    "PER_DEVICE_BATCH_SIZE = 2\n",
    "ALPHA = 1  # Weight for utility constraint\n",
    "THRESHOLD = 90  # Threshold to filter out salient modules\n",
    "\n",
    "# GPU configuration (set to empty string if no GPU available)\n",
    "# For multi-GPU, use: \"0,1,2,3\"\n",
    "CUDA_VISIBLE_DEVICES = \"0\"  # Adjust based on your GPU availability\n",
    "\n",
    "print(\"Unlearning Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Corpus: {CORPUS}\")\n",
    "print(f\"Algorithm: {ALGO}\")\n",
    "print(f\"Target Model: {TARGET_DIR}\")\n",
    "print(f\"Forget Data: {FORGET}\")\n",
    "print(f\"Retain Data: {RETAIN}\")\n",
    "print(f\"Output Directory: {OUT_DIR}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning Rate: {LR}\")\n",
    "print(f\"Batch Size: {PER_DEVICE_BATCH_SIZE}\")\n",
    "print(f\"GPU Devices: {CUDA_VISIBLE_DEVICES if CUDA_VISIBLE_DEVICES else 'CPU'}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running unlearning...\n",
      "Command: python /workspace/CS534L_Project/FailureLLMUnlearning/baselines/unlearn.py --algo ga --model_dir muse-bench/MUSE-News_target --tokenizer_dir meta-llama/Llama-2-7b-hf --data_file data/news/raw/forget.txt --retain_data_file data/news/raw/retain1.txt --out_dir ./ckpt/news/ga --max_len 2048 --epochs 10 --lr 1e-5 --alpha 1 --threshold 90 --per_device_batch_size 2\n",
      "\n",
      "‚ö† This may take a long time (hours for full training).\n",
      "‚ö† Make sure you have:\n",
      "   - Sufficient GPU memory (recommended: 16GB+ VRAM)\n",
      "   - HuggingFace access to download models\n",
      "   - Stable internet connection\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [01:35<00:00, 15.94s/it]\n",
      "  0%|          | 0/2040 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
      " 25%|‚ñà‚ñà‚ñç       | 500/2040 [09:13<28:26,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -87.0368, 'grad_norm': 113.5, 'learning_rate': 1e-05, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1000/2040 [18:26<19:13,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -101.4696, 'grad_norm': 114.5, 'learning_rate': 1e-05, 'epoch': 4.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1500/2040 [27:39<09:59,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -103.2278, 'grad_norm': 121.5, 'learning_rate': 1e-05, 'epoch': 7.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2000/2040 [36:54<00:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -104.5978, 'grad_norm': 118.0, 'learning_rate': 1e-05, 'epoch': 9.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2040/2040 [37:38<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2258.2066, 'train_samples_per_second': 1.802, 'train_steps_per_second': 0.903, 'train_loss': -99.20049235026042, 'epoch': 10.0}\n",
      "‚úì Unlearning completed successfully!\n",
      "Model saved to: ./ckpt/news/ga\n",
      "\n",
      "‚ö† To run unlearning, uncomment the code above and execute this cell.\n",
      "For now, we'll proceed with evaluation assuming you have a trained model.\n"
     ]
    }
   ],
   "source": [
    "# Run unlearning\n",
    "# Note: This will take a significant amount of time (potentially hours depending on epochs and GPU)\n",
    "# Make sure you have sufficient GPU memory and time\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Set environment variable for GPU\n",
    "if CUDA_VISIBLE_DEVICES:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = CUDA_VISIBLE_DEVICES\n",
    "\n",
    "# Build the command\n",
    "unlearn_script = repo_dir / \"baselines\" / \"unlearn.py\"\n",
    "\n",
    "cmd = [\n",
    "    \"python\", str(unlearn_script),\n",
    "    \"--algo\", ALGO,\n",
    "    \"--model_dir\", TARGET_DIR,\n",
    "    \"--tokenizer_dir\", TOKENIZER_DIR,\n",
    "    \"--data_file\", FORGET,\n",
    "    \"--retain_data_file\", RETAIN,\n",
    "    \"--out_dir\", OUT_DIR,\n",
    "    \"--max_len\", str(MAX_LEN),\n",
    "    \"--epochs\", str(EPOCHS),\n",
    "    \"--lr\", LR,\n",
    "    \"--alpha\", str(ALPHA),\n",
    "    \"--threshold\", str(THRESHOLD),\n",
    "    \"--per_device_batch_size\", str(PER_DEVICE_BATCH_SIZE)\n",
    "]\n",
    "\n",
    "print(\"Running unlearning...\")\n",
    "print(f\"Command: {' '.join(cmd)}\\n\")\n",
    "print(\"‚ö† This may take a long time (hours for full training).\")\n",
    "print(\"‚ö† Make sure you have:\")\n",
    "print(\"   - Sufficient GPU memory (recommended: 16GB+ VRAM)\")\n",
    "print(\"   - HuggingFace access to download models\")\n",
    "print(\"   - Stable internet connection\\n\")\n",
    "\n",
    "# Uncomment the following lines to actually run the unlearning\n",
    "result = subprocess.run(\n",
    "    cmd,\n",
    "    cwd=str(repo_dir),\n",
    "    capture_output=False,  # Set to True if you want to capture output\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úì Unlearning completed successfully!\")\n",
    "    print(f\"Model saved to: {OUT_DIR}\")\n",
    "else:\n",
    "    print(\"‚úó Error during unlearning:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "print(\"\\n‚ö† To run unlearning, uncomment the code above and execute this cell.\")\n",
    "print(\"For now, we'll proceed with evaluation assuming you have a trained model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Unlearned Models\n",
    "\n",
    "After training, we need to evaluate the unlearned models using various metrics:\n",
    "- `verbmem_f`: VerbMem Forget (measures if forgotten content is still generated)\n",
    "- `privleak`: PrivLeak (privacy leakage detection)\n",
    "- `knowmem_f`: KnowMem Forget (knowledge memorization on forget set)\n",
    "- `knowmem_r`: KnowMem Retain (utility - knowledge retention on retain set)\n",
    "\n",
    "We can evaluate models with different quantization settings:\n",
    "- Full precision: `quantize_4bit=0, quantize_8bit=0`\n",
    "- 4-bit quantization: `quantize_4bit=1, quantize_8bit=0`\n",
    "- 8-bit quantization: `quantize_4bit=0, quantize_8bit=1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä DETAILED RESULTS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üîç Model: original_target\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ UNLEARNING EFFECTIVENESS (Lower is Better):\n",
      "   Measures how well the model 'forgot' the target data\n",
      "\n",
      "   ‚Ä¢ verbmem_f (VerbMem Forget): 42.21%\n",
      "     ‚úó Poor: Model still memorizes verbatim text\n",
      "   ‚Ä¢ privleak (Privacy Leakage): -99.81%\n",
      "     ‚úì Excellent: Strong privacy protection\n",
      "   ‚Ä¢ knowmem_f (KnowMem Forget): 64.41%\n",
      "     ‚úó Poor: Model still has semantic knowledge\n",
      "\n",
      "‚úÖ UTILITY PRESERVATION (Higher is Better):\n",
      "   Measures how well the model retained general capabilities\n",
      "\n",
      "   ‚Ä¢ knowmem_r (KnowMem Retain): 53.91%\n",
      "     ‚ö† Significant: Notable utility degradation\n",
      "\n",
      "üìà OVERALL ASSESSMENT:\n",
      "--------------------------------------------------------------------------------\n",
      "   Unlearning Effectiveness: 31.2%\n",
      "   Utility Preservation: 53.9%\n",
      "\n",
      "   ‚ö† MODERATE: Balanced but not optimal performance.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed Results Analysis and Insights\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "OUTPUT_FILE = \"output.csv\"\n",
    "output_file = repo_dir / OUTPUT_FILE\n",
    "\n",
    "if output_file.exists():\n",
    "    df = pd.read_csv(output_file)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"üìä DETAILED RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Define metric categories\n",
    "    unlearning_metrics = ['verbmem_f', 'privleak', 'knowmem_f']  # Lower is better\n",
    "    utility_metrics = ['knowmem_r', 'gen', 'tru', 'fac', 'flu']  # Higher is better\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        model_name = row['name']\n",
    "        print(f\"üîç Model: {model_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Unlearning Effectiveness (Lower is Better)\n",
    "        print(\"\\n‚úÖ UNLEARNING EFFECTIVENESS (Lower is Better):\")\n",
    "        print(\"   Measures how well the model 'forgot' the target data\")\n",
    "        print()\n",
    "        \n",
    "        verbmem = row.get('verbmem_f', 0)\n",
    "        privleak = row.get('privleak', 0)\n",
    "        knowmem_f = row.get('knowmem_f', 0)\n",
    "        \n",
    "        print(f\"   ‚Ä¢ verbmem_f (VerbMem Forget): {verbmem:.2f}%\")\n",
    "        if verbmem < 20:\n",
    "            print(\"     ‚úì Excellent: Model cannot reproduce verbatim text\")\n",
    "        elif verbmem < 40:\n",
    "            print(\"     ‚ö† Moderate: Some verbatim memory remains\")\n",
    "        else:\n",
    "            print(\"     ‚úó Poor: Model still memorizes verbatim text\")\n",
    "        \n",
    "        print(f\"   ‚Ä¢ privleak (Privacy Leakage): {privleak:.2f}%\")\n",
    "        if privleak < -50:\n",
    "            print(\"     ‚úì Excellent: Strong privacy protection\")\n",
    "        elif privleak < 0:\n",
    "            print(\"     ‚úì Good: Better than retrained baseline\")\n",
    "        elif privleak < 20:\n",
    "            print(\"     ‚ö† Moderate: Some privacy leakage\")\n",
    "        else:\n",
    "            print(\"     ‚úó Poor: Significant privacy leakage detected\")\n",
    "        \n",
    "        print(f\"   ‚Ä¢ knowmem_f (KnowMem Forget): {knowmem_f:.2f}%\")\n",
    "        if knowmem_f < 20:\n",
    "            print(\"     ‚úì Excellent: Model cannot answer questions about forget set\")\n",
    "        elif knowmem_f < 40:\n",
    "            print(\"     ‚ö† Moderate: Some semantic knowledge remains\")\n",
    "        else:\n",
    "            print(\"     ‚úó Poor: Model still has semantic knowledge\")\n",
    "        \n",
    "        # Utility Preservation (Higher is Better)\n",
    "        print(\"\\n‚úÖ UTILITY PRESERVATION (Higher is Better):\")\n",
    "        print(\"   Measures how well the model retained general capabilities\")\n",
    "        print()\n",
    "        \n",
    "        knowmem_r = row.get('knowmem_r', 0)\n",
    "        gen = row.get('gen', 0)\n",
    "        tru = row.get('tru', 0)\n",
    "        fac = row.get('fac', 0)\n",
    "        flu = row.get('flu', 0)\n",
    "        \n",
    "        print(f\"   ‚Ä¢ knowmem_r (KnowMem Retain): {knowmem_r:.2f}%\")\n",
    "        if knowmem_r > 80:\n",
    "            print(\"     ‚úì Excellent: Utility well preserved\")\n",
    "        elif knowmem_r > 60:\n",
    "            print(\"     ‚ö† Moderate: Some utility loss\")\n",
    "        elif knowmem_r > 40:\n",
    "            print(\"     ‚ö† Significant: Notable utility degradation\")\n",
    "        else:\n",
    "            print(\"     ‚úó Poor: Catastrophic forgetting - model lost too much utility\")\n",
    "        \n",
    "        if gen > 0:\n",
    "            print(f\"   ‚Ä¢ gen (MMLU - General Knowledge): {gen:.2f}\")\n",
    "            if gen > 0.6:\n",
    "                print(\"     ‚úì Good: Model retains general knowledge\")\n",
    "            else:\n",
    "                print(\"     ‚ö† Low: General knowledge degraded\")\n",
    "        \n",
    "        if tru > 0:\n",
    "            print(f\"   ‚Ä¢ tru (TruthfulQA): {tru:.2f}\")\n",
    "            if tru > 0.6:\n",
    "                print(\"     ‚úì Good: Model remains truthful\")\n",
    "            else:\n",
    "                print(\"     ‚ö† Low: Truthfulness may be affected\")\n",
    "        \n",
    "        if fac > 0:\n",
    "            print(f\"   ‚Ä¢ fac (TriviaQA - Factual): {fac:.2f}\")\n",
    "            if fac > 0.5:\n",
    "                print(\"     ‚úì Good: Factual knowledge retained\")\n",
    "            else:\n",
    "                print(\"     ‚ö† Low: Factual knowledge degraded\")\n",
    "        \n",
    "        if flu > 0:\n",
    "            print(f\"   ‚Ä¢ flu (Fluency): {flu:.2f}\")\n",
    "            if flu > 0.7:\n",
    "                print(\"     ‚úì Good: Model remains fluent\")\n",
    "            else:\n",
    "                print(\"     ‚ö† Low: Fluency may be affected\")\n",
    "        \n",
    "        # Overall Assessment\n",
    "        print(\"\\nüìà OVERALL ASSESSMENT:\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Calculate unlearning score (average of normalized unlearning metrics)\n",
    "        unlearning_scores = []\n",
    "        if verbmem < 100:\n",
    "            unlearning_scores.append(1 - verbmem/100)  # Normalize to 0-1, higher is better\n",
    "        if privleak < 0:\n",
    "            unlearning_scores.append(1 - abs(privleak)/100)  # Negative privleak is good\n",
    "        if knowmem_f < 100:\n",
    "            unlearning_scores.append(1 - knowmem_f/100)\n",
    "        \n",
    "        avg_unlearning = np.mean(unlearning_scores) if unlearning_scores else 0\n",
    "        \n",
    "        # Calculate utility score\n",
    "        utility_scores = []\n",
    "        if knowmem_r > 0:\n",
    "            utility_scores.append(knowmem_r/100)\n",
    "        if gen > 0:\n",
    "            utility_scores.append(gen)\n",
    "        if tru > 0:\n",
    "            utility_scores.append(tru)\n",
    "        if fac > 0:\n",
    "            utility_scores.append(fac)\n",
    "        if flu > 0:\n",
    "            utility_scores.append(flu)\n",
    "        \n",
    "        avg_utility = np.mean(utility_scores) if utility_scores else 0\n",
    "        \n",
    "        print(f\"   Unlearning Effectiveness: {avg_unlearning*100:.1f}%\")\n",
    "        print(f\"   Utility Preservation: {avg_utility*100:.1f}%\")\n",
    "        print()\n",
    "        \n",
    "        # Trade-off analysis\n",
    "        if avg_unlearning > 0.7 and avg_utility > 0.7:\n",
    "            print(\"   üéâ EXCELLENT: Strong unlearning with good utility preservation!\")\n",
    "        elif avg_unlearning > 0.7 and avg_utility < 0.5:\n",
    "            print(\"   ‚ö† WARNING: Good unlearning but catastrophic utility loss!\")\n",
    "            print(\"      This may indicate quantization issues or overly aggressive unlearning.\")\n",
    "        elif avg_unlearning < 0.5 and avg_utility > 0.7:\n",
    "            print(\"   ‚ö† WARNING: Good utility but poor unlearning!\")\n",
    "            print(\"      The model may not have forgotten the target data effectively.\")\n",
    "        elif avg_unlearning < 0.5 and avg_utility < 0.5:\n",
    "            print(\"   ‚úó POOR: Both unlearning and utility are low.\")\n",
    "            print(\"      The unlearning process may have failed or damaged the model.\")\n",
    "        else:\n",
    "            print(\"   ‚ö† MODERATE: Balanced but not optimal performance.\")\n",
    "        \n",
    "        print()\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "    \n",
    "    # Comparative Analysis (if multiple models)\n",
    "    if len(df) > 1:\n",
    "        print(\"üìä COMPARATIVE ANALYSIS\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "        print(\"Comparing all models:\")\n",
    "        print()\n",
    "        \n",
    "        # Find best unlearning\n",
    "        best_unlearning = df.loc[df['verbmem_f'].idxmin()] if 'verbmem_f' in df.columns else None\n",
    "        if best_unlearning is not None:\n",
    "            print(f\"   Best Unlearning (lowest verbmem_f): {best_unlearning['name']} ({best_unlearning['verbmem_f']:.2f}%)\")\n",
    "        \n",
    "        # Find best utility\n",
    "        best_utility = df.loc[df['knowmem_r'].idxmax()] if 'knowmem_r' in df.columns else None\n",
    "        if best_utility is not None:\n",
    "            print(f\"   Best Utility (highest knowmem_r): {best_utility['name']} ({best_utility['knowmem_r']:.2f}%)\")\n",
    "        \n",
    "        # Find best balance\n",
    "        if 'verbmem_f' in df.columns and 'knowmem_r' in df.columns:\n",
    "            df['balance_score'] = (1 - df['verbmem_f']/100) * (df['knowmem_r']/100)\n",
    "            best_balance = df.loc[df['balance_score'].idxmax()]\n",
    "            print(f\"   Best Balance (unlearning √ó utility): {best_balance['name']} (score: {best_balance['balance_score']:.3f})\")\n",
    "        \n",
    "        print()\n",
    "        print(\"üí° TIP: For detailed insights, see RESULTS_INSIGHTS.md in the repository root.\")\n",
    "        print()\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ö† Results file {OUTPUT_FILE} not found yet.\")\n",
    "    print(\"Please run the evaluation step first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Analyze Results & Insights\n",
    "\n",
    "This section helps you interpret your evaluation results and understand what they mean for LLM unlearning effectiveness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Configuration:\n",
      "============================================================\n",
      "Models to evaluate: 1\n",
      "  - original_target: muse-bench/MUSE-News_target\n",
      "Corpus: news\n",
      "Metrics: verbmem_f, privleak, knowmem_f, knowmem_r\n",
      "Quantization: 4-bit=0, 8-bit=0\n",
      "Max samples: Full dataset\n",
      "Output file: output.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluation configuration\n",
    "\n",
    "# Models to evaluate (can be local paths or HuggingFace model IDs)\n",
    "# For this example, we'll evaluate the original target model\n",
    "# In practice, you would evaluate your unlearned models from the ckpt/ directory\n",
    "MODEL_DIRS = [\n",
    "    f\"muse-bench/MUSE-{CORPUS.capitalize()}_target\",  # Original target model\n",
    "    # Add your unlearned model paths here, e.g.:\n",
    "    # f\"./ckpt/{CORPUS}/{ALGO}\",\n",
    "]\n",
    "\n",
    "# Names for each model (should match length of MODEL_DIRS)\n",
    "MODEL_NAMES = [\n",
    "    \"original_target\",\n",
    "    # Add names for your models, e.g.:\n",
    "    # f\"{ALGO}_checkpoint_102\",\n",
    "]\n",
    "\n",
    "# Evaluation settings\n",
    "EVAL_CORPUS = CORPUS\n",
    "OUTPUT_FILE = \"output.csv\"\n",
    "TOKENIZER_DIR_EVAL = 'meta-llama/Llama-2-7b-hf'\n",
    "METRICS = ['verbmem_f', 'privleak', 'knowmem_f', 'knowmem_r']  # All metrics\n",
    "QUANTIZE_4BIT = 0  # Set to 1 for 4-bit quantization\n",
    "QUANTIZE_8BIT = 0  # Set to 1 for 8-bit quantization\n",
    "TEMP_DIR = \"temp\"\n",
    "MAX_SAMPLES = None # Set to a number (e.g., 10) to test with a small dataset first\n",
    "                     # None = use full dataset (recommended for final evaluation)\n",
    "\n",
    "print(\"Evaluation Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Models to evaluate: {len(MODEL_DIRS)}\")\n",
    "for name, model_dir in zip(MODEL_NAMES, MODEL_DIRS):\n",
    "    print(f\"  - {name}: {model_dir}\")\n",
    "print(f\"Corpus: {EVAL_CORPUS}\")\n",
    "print(f\"Metrics: {', '.join(METRICS)}\")\n",
    "print(f\"Quantization: 4-bit={QUANTIZE_4BIT}, 8-bit={QUANTIZE_8BIT}\")\n",
    "print(f\"Max samples: {MAX_SAMPLES if MAX_SAMPLES else 'Full dataset'}\")\n",
    "print(f\"Output file: {OUTPUT_FILE}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Using cached rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from rouge) (1.16.0)\n",
      "Using cached rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.3.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.1.2)\n",
      "Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.16.3\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Installing collected packages: safetensors, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/5\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.2.0 huggingface-hub-0.36.0 safetensors-0.7.0 tokenizers-0.22.1 transformers-4.57.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.1.2)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Using cached multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Using cached aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "Using cached multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Using cached pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12/12\u001b[0m [datasets]/12\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 datasets-4.4.1 dill-0.4.0 frozenlist-1.8.0 multidict-6.7.0 multiprocess-0.70.18 propcache-0.4.1 pyarrow-22.0.0 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu128)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft) (4.67.1)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.7.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft) (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.10.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (0.22.1)\n",
      "Downloading peft-0.18.0-py3-none-any.whl (556 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Installing collected packages: accelerate, peft\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [peft][32m1/2\u001b[0m [peft]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 peft-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trl>=0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate) (2025.10.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.12/dist-packages (from scipy->bitsandbytes) (1.26.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -i https://pypi.org/simple/ bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.12/dist-packages (from scipy->bitsandbytes) (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -i https://pypi.org/simple/ bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Command: /usr/local/bin/python /workspace/CS534L_Project/FailureLLMUnlearning/eval.py --model_dirs muse-bench/MUSE-News_target --names original_target --corpus news --out_file output.csv --tokenizer_dir meta-llama/Llama-2-7b-hf --metrics verbmem_f privleak knowmem_f knowmem_r --temp_dir temp --quantize_4bit 0 --quantize_8bit 0 --alpha 5\n",
      "\n",
      "‚ö† This may take a long time depending on:\n",
      "   - Number of models to evaluate\n",
      "   - Model size\n",
      "   - Number of metrics\n",
      "   - GPU availability\n",
      "\n",
      "‚úì Evaluation completed successfully!\n",
      "Results saved to: output.csv\n",
      "\n",
      "Output:\n",
      "model_dir: muse-bench/MUSE-News_target\n",
      "Load model in full-precision\n",
      "Evaluating on the forget set...\n",
      "Evaluating on the retain set...\n",
      "Evaluating on the holdout set...\n",
      "[{'name': 'original_target', 'verbmem_f': 42.213480520485334, 'privleak': -99.8113998323554, 'knowmem_f': 64.40881690548873, 'knowmem_r': 53.9108123677155, 'gen': 0.0, 'tru': 0.0, 'fac': 0.0, 'flu': 0.0}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "# Note: Evaluation can also take a significant amount of time\n",
    "# Each metric requires running inference on the model\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if required variables are defined (from Cell 17)\n",
    "required_vars = ['repo_dir', 'MODEL_DIRS', 'MODEL_NAMES', 'EVAL_CORPUS', \n",
    "                 'OUTPUT_FILE', 'TOKENIZER_DIR_EVAL', 'METRICS', 'TEMP_DIR',\n",
    "                 'QUANTIZE_4BIT', 'QUANTIZE_8BIT', 'MAX_SAMPLES']\n",
    "missing_vars = [v for v in required_vars if v not in globals()]\n",
    "if missing_vars:\n",
    "    print(\"Error: Missing required variables. Please run Cell 17 (Evaluation Configuration) first.\")\n",
    "    print(f\"Missing variables: {', '.join(missing_vars)}\")\n",
    "    raise NameError(f\"Missing variables: {', '.join(missing_vars)}. Please run Cell 17 first.\")\n",
    "\n",
    "\n",
    "# Set CUDA devices safely\n",
    "cuda_env = globals().get(\"CUDA_VISIBLE_DEVICES\") or os.environ.get(\"CUDA_VISIBLE_DEVICES\")\n",
    "if cuda_env:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_env\n",
    "else:\n",
    "    os.environ.pop(\"CUDA_VISIBLE_DEVICES\", None)\n",
    "\n",
    "# Define eval script and Python executable\n",
    "eval_script = repo_dir / \"eval.py\"\n",
    "python_executable = sys.executable\n",
    "\n",
    "# Alpha parameter required by load_model function\n",
    "ALPHA_EVAL = 5  # Default alpha value for evaluation\n",
    "\n",
    "# --- Build the command ---\n",
    "cmd = (\n",
    "    [python_executable, str(eval_script)]\n",
    "    + [\"--model_dirs\"] + MODEL_DIRS\n",
    "    + [\"--names\"] + MODEL_NAMES\n",
    "    + [\"--corpus\", EVAL_CORPUS,\n",
    "       \"--out_file\", OUTPUT_FILE,\n",
    "       \"--tokenizer_dir\", TOKENIZER_DIR_EVAL,\n",
    "       \"--metrics\"] + METRICS\n",
    "    + [\"--temp_dir\", TEMP_DIR,\n",
    "       \"--quantize_4bit\", str(int(QUANTIZE_4BIT)),\n",
    "       \"--quantize_8bit\", str(int(QUANTIZE_8BIT)),\n",
    "       \"--alpha\", str(ALPHA_EVAL)]\n",
    ")\n",
    "\n",
    "# Add max_samples if specified (for quick testing)\n",
    "if MAX_SAMPLES is not None:\n",
    "    cmd = cmd + [\"--max_samples\", str(MAX_SAMPLES)]\n",
    "\n",
    "# --- Run the evaluation ---\n",
    "print(\"Starting evaluation...\")\n",
    "print(f\"Command: {' '.join(cmd)}\\n\")\n",
    "if MAX_SAMPLES is not None:\n",
    "    print(f\"‚ö† Quick test mode: Using only {MAX_SAMPLES} samples per metric\")\n",
    "    print(\"   This is much faster for testing. Set MAX_SAMPLES=None for full evaluation.\\n\")\n",
    "else:\n",
    "    print(\"‚ö† This may take a long time depending on:\")\n",
    "    print(\"   - Number of models to evaluate\")\n",
    "    print(\"   - Model size\")\n",
    "    print(\"   - Number of metrics\")\n",
    "    print(\"   - GPU availability\\n\")\n",
    "\n",
    "result = subprocess.run(cmd, cwd=str(repo_dir), capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úì Evaluation completed successfully!\")\n",
    "    print(f\"Results saved to: {OUTPUT_FILE}\")\n",
    "    if result.stdout:\n",
    "        print(\"\\nOutput:\")\n",
    "        print(result.stdout)\n",
    "else:\n",
    "    print(\"‚úó Error during evaluation:\")\n",
    "    print(\"=\" * 60)\n",
    "    if result.stdout:\n",
    "        print(\"STDOUT:\")\n",
    "        print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(\"\\nSTDERR:\")\n",
    "        print(result.stderr)\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # --- Common error hints ---\n",
    "    error_output = (result.stdout + result.stderr).lower()\n",
    "    if \"nameerror\" in error_output or \"name 'args'\" in error_output:\n",
    "        print(\"\\n‚ö† Hint: Check eval.py ‚Äî replace any 'args' references with function parameters.\")\n",
    "    elif \"import\" in error_output or \"module\" in error_output:\n",
    "        print(\"\\n‚ö† Hint: Import error detected. Ensure dependencies are installed (pip install -r requirements.txt).\")\n",
    "    elif \"cuda\" in error_output or \"gpu\" in error_output:\n",
    "        print(\"\\n‚ö† Hint: GPU/CUDA issue detected. On macOS, set quantize_4bit=0 and quantize_8bit=0.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate) (2025.10.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (0.29.0)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.29.0\n",
      "    Uninstalling accelerate-0.29.0:\n",
      "      Successfully uninstalled accelerate-0.29.0\n",
      "Successfully installed accelerate-1.12.0\n",
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.12/dist-packages (from scipy->bitsandbytes) (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade accelerate\n",
    "!{sys.executable} -m pip install -i https://pypi.org/simple/ bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Command: /usr/local/bin/python /workspace/CS534L_Project/FailureLLMUnlearning/eval.py --model_dirs muse-bench/MUSE-News_target --names original_target --corpus news --out_file output.csv --tokenizer_dir meta-llama/Llama-2-7b-hf --metrics verbmem_f privleak knowmem_f knowmem_r --temp_dir temp --quantize_4bit 0 --quantize_8bit 0 --alpha 5\n",
      "\n",
      "‚ö† This may take a long time depending on:\n",
      "   - Number of models to evaluate\n",
      "   - Model size\n",
      "   - Number of metrics\n",
      "   - GPU availability\n",
      "\n",
      "‚úó Error during evaluation:\n",
      "============================================================\n",
      "STDOUT:\n",
      "model_dir: muse-bench/MUSE-News_target\n",
      "Load model in full-precision\n",
      "\n",
      "\n",
      "STDERR:\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/CS534L_Project/FailureLLMUnlearning/eval.py\", line 262, in <module>\n",
      "    load_then_eval_models(**args_dict)\n",
      "  File \"/workspace/CS534L_Project/FailureLLMUnlearning/eval.py\", line 224, in load_then_eval_models\n",
      "    model = load_model(model_dir, model_name, quantize_4bit_int, quantize_8bit_int, alpha, corpus=corpus)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/CS534L_Project/FailureLLMUnlearning/utils.py\", line 125, in load_model\n",
      "    return AutoModelForCausalLM.from_pretrained(model_dir,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\", line 563, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 3550, in from_pretrained\n",
      "    model = cls(config, *model_args, **model_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: LlamaForCausalLM.__init__() got an unexpected keyword argument 'dtype'\n",
      "\n",
      "============================================================\n",
      "\n",
      "‚ö† Hint: Import error detected. Ensure dependencies are installed (pip install -r requirements.txt).\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "# Note: Evaluation can also take a significant amount of time\n",
    "# Each metric requires running inference on the model\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if required variables are defined (from Cell 17)\n",
    "required_vars = ['repo_dir', 'MODEL_DIRS', 'MODEL_NAMES', 'EVAL_CORPUS', \n",
    "                 'OUTPUT_FILE', 'TOKENIZER_DIR_EVAL', 'METRICS', 'TEMP_DIR',\n",
    "                 'QUANTIZE_4BIT', 'QUANTIZE_8BIT', 'MAX_SAMPLES']\n",
    "missing_vars = [v for v in required_vars if v not in globals()]\n",
    "if missing_vars:\n",
    "    print(\"Error: Missing required variables. Please run Cell 17 (Evaluation Configuration) first.\")\n",
    "    print(f\"Missing variables: {', '.join(missing_vars)}\")\n",
    "    raise NameError(f\"Missing variables: {', '.join(missing_vars)}. Please run Cell 17 first.\")\n",
    "\n",
    "# Set CUDA devices safely\n",
    "CUDA_VISIBLE_DEVICES = os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"\")\n",
    "if 'CUDA_VISIBLE_DEVICES' in globals() and globals()['CUDA_VISIBLE_DEVICES']:\n",
    "    CUDA_VISIBLE_DEVICES = globals()['CUDA_VISIBLE_DEVICES']\n",
    "\n",
    "# Apply CUDA device visibility\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA_VISIBLE_DEVICES\n",
    "\n",
    "# Define eval script and Python executable\n",
    "eval_script = repo_dir / \"eval.py\"\n",
    "python_executable = sys.executable\n",
    "\n",
    "# Alpha parameter required by load_model function\n",
    "ALPHA_EVAL = 5  # Default alpha value for evaluation\n",
    "\n",
    "# --- Build the command ---\n",
    "cmd = (\n",
    "    [python_executable, str(eval_script)]\n",
    "    + [\"--model_dirs\"] + MODEL_DIRS\n",
    "    + [\"--names\"] + MODEL_NAMES\n",
    "    + [\"--corpus\", EVAL_CORPUS,\n",
    "       \"--out_file\", OUTPUT_FILE,\n",
    "       \"--tokenizer_dir\", TOKENIZER_DIR_EVAL,\n",
    "       \"--metrics\"] + METRICS\n",
    "    + [\"--temp_dir\", TEMP_DIR,\n",
    "       \"--quantize_4bit\", str(int(QUANTIZE_4BIT)),\n",
    "       \"--quantize_8bit\", str(int(QUANTIZE_8BIT)),\n",
    "       \"--alpha\", str(ALPHA_EVAL)]\n",
    ")\n",
    "\n",
    "# Add max_samples if specified (for quick testing)\n",
    "if MAX_SAMPLES is not None:\n",
    "    cmd = cmd + [\"--max_samples\", str(MAX_SAMPLES)]\n",
    "\n",
    "# --- Run the evaluation ---\n",
    "print(\"Starting evaluation...\")\n",
    "print(f\"Command: {' '.join(cmd)}\\n\")\n",
    "if MAX_SAMPLES is not None:\n",
    "    print(f\"‚ö† Quick test mode: Using only {MAX_SAMPLES} samples per metric\")\n",
    "    print(\"   This is much faster for testing. Set MAX_SAMPLES=None for full evaluation.\\n\")\n",
    "else:\n",
    "    print(\"‚ö† This may take a long time depending on:\")\n",
    "    print(\"   - Number of models to evaluate\")\n",
    "    print(\"   - Model size\")\n",
    "    print(\"   - Number of metrics\")\n",
    "    print(\"   - GPU availability\\n\")\n",
    "\n",
    "result = subprocess.run(cmd, cwd=str(repo_dir), capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úì Evaluation completed successfully!\")\n",
    "    print(f\"Results saved to: {OUTPUT_FILE}\")\n",
    "    if result.stdout:\n",
    "        print(\"\\nOutput:\")\n",
    "        print(result.stdout)\n",
    "else:\n",
    "    print(\"‚úó Error during evaluation:\")\n",
    "    print(\"=\" * 60)\n",
    "    if result.stdout:\n",
    "        print(\"STDOUT:\")\n",
    "        print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(\"\\nSTDERR:\")\n",
    "        print(result.stderr)\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # --- Common error hints ---\n",
    "    error_output = (result.stdout + result.stderr).lower()\n",
    "    if \"nameerror\" in error_output or \"name 'args'\" in error_output:\n",
    "        print(\"\\n‚ö† Hint: Check eval.py ‚Äî replace any 'args' references with function parameters.\")\n",
    "    elif \"import\" in error_output or \"module\" in error_output:\n",
    "        print(\"\\n‚ö† Hint: Import error detected. Ensure dependencies are installed (pip install -r requirements.txt).\")\n",
    "    elif \"cuda\" in error_output or \"gpu\" in error_output:\n",
    "        print(\"\\n‚ö† Hint: GPU/CUDA issue detected. On macOS, set quantize_4bit=0 and quantize_8bit=0.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: View Results\n",
    "\n",
    "After evaluation completes, we can load and display the results from the output CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results from output.csv...\n",
      "\n",
      "Evaluation Results:\n",
      "================================================================================\n",
      "           name  verbmem_f  privleak  knowmem_f  knowmem_r  gen  tru  fac  flu\n",
      "original_target        0.0    -100.0        0.0        0.0  0.0  0.0  0.0  0.0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load and display results\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "output_file = repo_dir / OUTPUT_FILE\n",
    "\n",
    "if output_file.exists():\n",
    "    print(f\"Loading results from {OUTPUT_FILE}...\\n\")\n",
    "    df = pd.read_csv(output_file)\n",
    "    \n",
    "    # Display the results\n",
    "    print(\"Evaluation Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display summary statistics if multiple models\n",
    "    if len(df) > 1:\n",
    "        print(\"\\nSummary Statistics:\")\n",
    "        print(\"=\" * 80)\n",
    "        numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            print(df[numeric_cols].describe())\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ö† Results file {OUTPUT_FILE} not found yet.\")\n",
    "    print(\"Please run the evaluation step first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Notes and Tips\n",
    "\n",
    "### Running Multiple Algorithms\n",
    "\n",
    "To run multiple unlearning algorithms, you can modify the configuration in Step 5:\n",
    "\n",
    "```python\n",
    "algorithms = ['ga', 'ga_gdr', 'npo', 'npo_gdr']\n",
    "for algo in algorithms:\n",
    "    # Run unlearning for each algorithm\n",
    "    ...\n",
    "```\n",
    "\n",
    "### Using Different Corpora\n",
    "\n",
    "You can switch between News and Books corpora by changing:\n",
    "```python\n",
    "CORPUS = 'books'  # or 'news'\n",
    "```\n",
    "\n",
    "### Quantization Testing\n",
    "\n",
    "To test models with different quantization settings, modify the evaluation step:\n",
    "- Full precision: `QUANTIZE_4BIT=0, QUANTIZE_8BIT=0`\n",
    "- 4-bit: `QUANTIZE_4BIT=1, QUANTIZE_8BIT=0`\n",
    "- 8-bit: `QUANTIZE_4BIT=0, QUANTIZE_8BIT=1`\n",
    "\n",
    "### GPU Requirements\n",
    "\n",
    "- **Recommended**: NVIDIA GPU with 16GB+ VRAM\n",
    "- For smaller GPUs, reduce `PER_DEVICE_BATCH_SIZE` or use quantization\n",
    "- For CPU-only, expect significantly longer training times\n",
    "\n",
    "### Time Estimates\n",
    "\n",
    "- **Data loading**: 5-15 minutes\n",
    "- **Unlearning (1 epoch)**: 1-4 hours (depending on GPU)\n",
    "- **Evaluation**: 30 minutes - 2 hours per model\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "1. **HuggingFace access**: Make sure you're logged in: `huggingface-cli login`\n",
    "2. **CUDA errors**: Check GPU availability and CUDA installation\n",
    "3. **Memory errors**: Reduce batch size or use gradient checkpointing\n",
    "4. **Import errors**: Ensure all dependencies are installed correctly\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Experiment with different algorithms\n",
    "2. Try different hyperparameters (learning rate, epochs, alpha, threshold)\n",
    "3. Compare results across different quantization settings\n",
    "4. Analyze the trade-offs between unlearning effectiveness and model utility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference: Shell Commands\n",
    "\n",
    "If you prefer to run commands directly in the terminal instead of through this notebook, here are the key commands:\n",
    "\n",
    "### 1. Clone Repository\n",
    "```bash\n",
    "cd /Users/himanshumishra/Library/CloudStorage/OneDrive-UBC/UBC/Term1/Projects\n",
    "git clone https://github.com/zzwjames/FailureLLMUnlearning.git\n",
    "cd FailureLLMUnlearning\n",
    "```\n",
    "\n",
    "### 2. Create Conda Environment\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "conda activate py310\n",
    "```\n",
    "\n",
    "### 3. Install Dependencies (Alternative to conda)\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 4. Load Data\n",
    "```bash\n",
    "python load_data.py\n",
    "```\n",
    "\n",
    "### 5. Run Unlearning (Example)\n",
    "```bash\n",
    "cd baselines\n",
    "python unlearn.py \\\n",
    "    --algo ga \\\n",
    "    --model_dir muse-bench/MUSE-News_target \\\n",
    "    --tokenizer_dir meta-llama/Llama-2-7b-hf \\\n",
    "    --data_file ../data/news/raw/forget.txt \\\n",
    "    --retain_data_file ../data/news/raw/retain1.txt \\\n",
    "    --out_dir ../ckpt/news/ga \\\n",
    "    --max_len 2048 \\\n",
    "    --epochs 10 \\\n",
    "    --lr 1e-5 \\\n",
    "    --alpha 1 \\\n",
    "    --threshold 90 \\\n",
    "    --per_device_batch_size 2\n",
    "```\n",
    "\n",
    "### 6. Evaluate Models\n",
    "```bash\n",
    "cd ..  # Back to repository root\n",
    "python eval.py \\\n",
    "    --model_dirs \"muse-bench/MUSE-News_target\" \\\n",
    "    --names \"original\" \\\n",
    "    --corpus news \\\n",
    "    --out_file \"output.csv\" \\\n",
    "    --quantize_4bit 0 \\\n",
    "    --quantize_8bit 0\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
